# HÆ°á»›ng Dáº«n Train Model Cho Cá»­a HÃ ng Äá»“ng Há»“

## ğŸ¯ PhÆ°Æ¡ng PhÃ¡p 1: Prompt Engineering (KHUYÃŠN DÃ™NG)

**Æ¯u Ä‘iá»ƒm:** Nhanh, dá»…, khÃ´ng cáº§n training
**Thá»i gian:** 5 phÃºt

### ÄÃ£ triá»ƒn khai:

System prompts chuyÃªn biá»‡t cho cá»­a hÃ ng Ä‘á»“ng há»“
PhÃ¡t hiá»‡n Ã½ Ä‘á»‹nh tá»± Ä‘á»™ng (tÆ° váº¥n/quáº£n lÃ½)  
Context sáº£n pháº©m Ä‘á»™ng
Endpoint `/chat/watch-advisor` chuyÃªn biá»‡t

### Sá»­ dá»¥ng:

```bash
curl -X POST http://127.0.0.1:8000/chat/watch-advisor \
-H "Content-Type: application/json" \
-d '{"message": "TÃ´i muá»‘n mua Ä‘á»“ng há»“ nam giÃ¡ 5 triá»‡u"}'
```

## ğŸ”§ PhÆ°Æ¡ng PhÃ¡p 2: Fine-tuning Mistral (NÃ¢ng cao)

### BÆ°á»›c 1: Chuáº©n bá»‹ dá»¯ liá»‡u

```python
# File: prepare_training_data.py
import json

# Chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u training thÃ nh format Mistral
training_data = []
for item in WATCH_TRAINING_DATA:
    formatted = {
        "messages": [
            {"role": "system", "content": WATCH_STORE_SYSTEM_PROMPT},
            {"role": "user", "content": item["input"]},
            {"role": "assistant", "content": item["output"]}
        ]
    }
    training_data.append(formatted)

# LÆ°u file JSONL
with open("watch_training.jsonl", "w", encoding="utf-8") as f:
    for item in training_data:
        f.write(json.dumps(item, ensure_ascii=False) + "\n")
```

### BÆ°á»›c 2: Fine-tuning vá»›i HuggingFace

```python
# pip install transformers datasets peft accelerate
from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer
from datasets import Dataset
import torch

# Load model vÃ  tokenizer
model_name = "mistralai/Mistral-7B-Instruct-v0.3"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16)

# Setup LoRA (Low-Rank Adaptation)
from peft import LoraConfig, get_peft_model, TaskType

lora_config = LoraConfig(
    task_type=TaskType.CAUSAL_LM,
    inference_mode=False,
    r=8,
    lora_alpha=32,
    lora_dropout=0.1
)

model = get_peft_model(model, lora_config)

# Training arguments
training_args = TrainingArguments(
    output_dir="./watch-mistral-finetuned",
    num_train_epochs=3,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=2,
    warmup_steps=10,
    logging_steps=1,
    save_strategy="epoch",
    evaluation_strategy="no",
    learning_rate=2e-4,
    fp16=True,
)

# Train
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset,
    tokenizer=tokenizer,
)

trainer.train()
```

### BÆ°á»›c 3: Sá»­ dá»¥ng model Ä‘Ã£ train

```python
# Load fine-tuned model
from peft import PeftModel

base_model = AutoModelForCausalLM.from_pretrained("mistralai/Mistral-7B-Instruct-v0.3")
model = PeftModel.from_pretrained(base_model, "./watch-mistral-finetuned")
```

## ğŸš€ PhÆ°Æ¡ng PhÃ¡p 3: RAG (Retrieval-Augmented Generation)

### CÃ i Ä‘áº·t vector database

```python
# pip install chromadb sentence-transformers
import chromadb
from sentence_transformers import SentenceTransformer

# Táº¡o vector database vá»›i thÃ´ng tin sáº£n pháº©m
client = chromadb.Client()
collection = client.create_collection(name="watches")

# Embed sáº£n pháº©m
embedder = SentenceTransformer('all-MiniLM-L6-v2')

products = [
    "Rolex Submariner: Äá»“ng há»“ láº·n cao cáº¥p, chá»‘ng nÆ°á»›c 300m, giÃ¡ 250 triá»‡u",
    "Omega Speedmaster: Äá»“ng há»“ phi hÃ nh gia, chronograph, giÃ¡ 150 triá»‡u",
    "Citizen Eco-Drive: Äá»“ng há»“ nÄƒng lÆ°á»£ng máº·t trá»i, giÃ¡ 5 triá»‡u"
]

for i, product in enumerate(products):
    embedding = embedder.encode(product)
    collection.add(
        embeddings=[embedding],
        documents=[product],
        ids=[str(i)]
    )
```

### TÃ­ch há»£p RAG vÃ o AI client

```python
# Trong ai_client.py
async def generate_with_context(self, prompt: str, context_docs: list = None):
    if context_docs:
        context = "\n".join([f"- {doc}" for doc in context_docs])
        enhanced_prompt = f"Context sáº£n pháº©m:\n{context}\n\nKhÃ¡ch hÃ ng: {prompt}\n\nTráº£ lá»i:"
    else:
        enhanced_prompt = prompt

    return await self.generate(enhanced_prompt)
```

## ğŸ“Š So sÃ¡nh cÃ¡c phÆ°Æ¡ng phÃ¡p

| PhÆ°Æ¡ng phÃ¡p        | Äá»™ khÃ³     | Thá»i gian | Hiá»‡u quáº£   | Chi phÃ­  |
| ------------------ | ---------- | --------- | ---------- | -------- |
| Prompt Engineering | â­         | 5 phÃºt    | â­â­â­â­   | Miá»…n phÃ­ |
| Fine-tuning        | â­â­â­â­â­ | 2-4 giá»   | â­â­â­â­â­ | GPU cao  |
| RAG                | â­â­â­     | 30 phÃºt   | â­â­â­â­   | Tháº¥p     |

## ğŸ‰ Káº¿t luáº­n

**KhuyÃªn dÃ¹ng:** Báº¯t Ä‘áº§u vá»›i Prompt Engineering (Ä‘Ã£ triá»ƒn khai), sau Ä‘Ã³ thÃªm RAG náº¿u cáº§n context phá»©c táº¡p hÆ¡n.

Fine-tuning chá»‰ cáº§n thiáº¿t khi:

- CÃ³ >1000 cÃ¢u há»i training cháº¥t lÆ°á»£ng cao
- Cáº§n phong cÃ¡ch tráº£ lá»i ráº¥t Ä‘áº·c biá»‡t
- CÃ³ ngÃ¢n sÃ¡ch GPU training

## ğŸ”§ Sá»­ dá»¥ng ngay

Server hiá»‡n táº¡i Ä‘Ã£ cÃ³:

- `/chat/` - Chat thÃ´ng minh vá»›i detect intent
- `/chat/watch-advisor` - TÆ° váº¥n chuyÃªn biá»‡t Ä‘á»“ng há»“
- `/chat/crud` - Quáº£n lÃ½ sáº£n pháº©m

HÃ£y test thá»­ vÃ  feedback Ä‘á»ƒ tÃ´i cáº£i thiá»‡n!
